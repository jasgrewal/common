#What is PCA?
- Part of a family of methods, but most commonly used
	- *There are two books devoted solely to principal components...which we think overstates its value as a technique*. \[Venables and Riply, Modern Applied Statistics with S \]
- It is **unsupervised**, like clustering
	- Used to summarize the data, dimensionality reduction
- Underlying object is a data vector
	- Instead of looking at the high dim space, look at parts of it (up to 3 dims)
	- or we can look at projections into a 2D space we can visualize
- Aim is to get a more compact representation of the data
	- Components may contribute to explanations and/or corrections to the data model
	- definition of good starts with "find the direction in the data that has the largest variance" (different than **ICA** - Independent Component Analysis)

##Correlation matrix
###Start with covariance matrix
- (X <sup>T</sup> * X) / (n-1)
- If the samples are perfectly correlated, the *column data* will look identical 
	- If there is no correlation among the samples 
	- Two types of samples, perfectly correlated within the groups, and completely uncorrelated across, get 2 blocks

###Basis and Span

**It makes a difference if you standardize or not, before PCA**
- Double-standardize the data so the rows and columns both have mean 0 and variance 1
- Unsupervised vs supervised PCA ([see this](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1851158))

Scree plot
- When data is all noise, equal amount of variance in all directions, so flat line
- shows relative magnitudes of eigenvalues (steep plot = lot of global correlation structure in the data)

If you remove the first 10 components and ran SVD on that data, the scree plot will be flatter, and last 10 eigenvalues will be 0 (since effectively removed 10...flattened the data out in ten directions). 

Visualization with a biplot (if limited number of genes)
